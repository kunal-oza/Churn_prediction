ğŸ“˜ Customer Churn Prediction System

Machine Learning + FastAPI API + Streamlit UI + Supabase PostgreSQL + Docker

ğŸš€ Overview

This project is a complete end-to-end churn prediction platform, combining:

Machine Learning Model (Logistic Regression + ColumnTransformer pipeline)

FastAPI Backend for prediction & data storage

Supabase PostgreSQL Database with connected tables

Streamlit Frontend for user input & results

Docker for deployment

The system:

Accepts customer information

Saves customer data in UserData table

Runs churn prediction

Stores prediction in Prediction table

Returns results to Streamlit instant UI

ğŸ—„ï¸ Database Integration (Supabase)

The system now uses Supabase PostgreSQL as the central database with two relational tables, fully connected.

ğŸ“Œ 1. UserData Table

Stores all customer profile information.

Column	Type	Description
CustomerID	String (PK)	Unique customer identifier
gender	String	Male / Female
SeniorCitizen	Integer	0 or 1
Partner	String	Yes / No
Dependents	String	Yes / No
tenure	Integer	Months with company
PhoneService	String	Yes / No
...	...	All remaining churn-related fields

SQLAlchemy model:

class UserData(Base):
    __tablename__ = "UserData"
    CustomerID = Column(String, primary_key=True, index=True)
    gender = Column(String)
    SeniorCitizen = Column(Integer)
    Partner = Column(String)
    Dependents = Column(String)
    tenure = Column(Integer)
    PhoneService = Column(String)
    MultipleLines = Column(String)
    InternetService = Column(String)
    OnlineSecurity = Column(String)
    OnlineBackup = Column(String)
    DeviceProtection = Column(String)
    TechSupport = Column(String)
    StreamingTV = Column(String)
    StreamingMovies = Column(String)
    Contract = Column(String)
    PaperlessBilling = Column(String)
    PaymentMethod = Column(String)
    MonthlyCharges = Column(Float)
    total_charges = Column(Float)

    # Relationship to predictions
    predictions = relationship("Prediction", back_populates="user")

ğŸ“Œ 2. Prediction Table

Stores the churn prediction result for each customer.

Column	Type	Description
id	Integer (PK)	Auto-increment
customer_id	String (FK â†’ UserData.CustomerID)	Linked customer
label	String	Churn / Not Churn

SQLAlchemy model:

class Prediction(Base):
    __tablename__ = "predictions"

    id = Column(Integer, primary_key=True, index=True)
    customer_id = Column(String, ForeignKey("UserData.CustomerID"))
    label = Column(String)

    # Relationship link to customer
    user = relationship("UserData", back_populates="predictions")

ğŸ”— Database Relationship
UserData.CustomerID   1  â”€â”€â”€â”€â”€â”€â”€â”€â”€>  many  Prediction.customer_id


This means:

Each customer can have multiple predictions

Each prediction is tied to only one customer

âš™ï¸ FastAPI Workflow (Updated)
âœ” 1. Receive input

FastAPI receives customer info validated by Pydantic.

âœ” 2. Save / Update UserData

If the customer exists â†’ update row
If new â†’ insert row

âœ” 3. Run ML Model

Prediction is generated using the pre-trained Scikit model.

âœ” 4. Save prediction

Result is stored in predictions table with FK.

âœ” 5. Respond to Streamlit

Response contains:

{
  "CustomerID": 1001,
  "Label": "Churn",
}

ğŸ–¥ï¸ Project Structure
â”‚   Dockerfile
â”‚   main.py
â”‚   .env
â”‚   requirements.txt
â”‚   __init__.py
â”‚   .env   â† Supabase DATABASE_URL stored here
â”‚
â”œâ”€â”€ model
â”‚     â”œâ”€â”€ logistic_regression_model.pkl
â”‚     â””â”€â”€ model_loading.py
â”‚
â”œâ”€â”€ preprocessing
â”‚     â””â”€â”€ pydentic.py
â”‚
â”œâ”€â”€ ui
â”‚     â””â”€â”€ frontend.py  (Streamlit UI)
â”‚
â””â”€â”€ database
      â”œâ”€â”€ db.py        (SQLAlchemy engine + Supabase connection)
      â”œâ”€â”€ models.py    (UserData + Prediction)
      â””â”€â”€ __init__.py

ğŸ”§ Local Setup
1ï¸âƒ£ Create a virtual environment
python -m venv venv
source venv/bin/activate    # Windows: venv\Scripts\activate

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

3ï¸âƒ£ Start FastAPI
uvicorn main:app --reload

4ï¸âƒ£ Start Streamlit
streamlit run ui/frontend.py

ğŸ³ Docker Deployment
Build image:
docker build -t churn-app .

Run container:
docker run -p 8000:8000 -p 8501:8501 \
  --env-file .env \
  --name churn-container churn-app


.env contains:

DATABASE_URL=postgresql+psycopg2://postgres:PASSWORD@db.xyz.supabase.co:5432/postgres

ğŸ“¡ API Example
Request
{
  "CustomerID": 1002,
  "gender": "Male",
  "SeniorCitizen": 0,
  "Partner": "No",
  "Dependents": "No",
  "tenure": 12,
  "PhoneService": "Yes",
  "MultipleLines": "No",
  "InternetService": "DSL",
  "OnlineSecurity": "No",
  "OnlineBackup": "No",
  "DeviceProtection": "Yes",
  "TechSupport": "No",
  "StreamingTV": "Yes",
  "StreamingMovies": "No",
  "Contract": "Month-to-month",
  "PaperlessBilling": "Yes",
  "PaymentMethod": "Electronic check",
  "MonthlyCharges": 70.5,
  "total_charges": 1000.0
}

Response
{
  "CustomerID": 1002,
  "Label": "Churn",
}

ğŸ¨ Key Features

âœ” Linked database tables (UserData â†” Prediction)
âœ” FastAPI backend with validation & DB persistence
âœ” Streamlit modern frontend UI
âœ” ML model loading + preprocessing
âœ” Dockerized for easy deployment
âœ” Production-grade PostgreSQL using Supabase

ğŸš€ Future Enhancements

Add prediction probability

Add timestamps

Add user history endpoint

Display predictions history in Streamlit

Admin dashboard

Batch CSV prediction

ğŸ Final Notes

Your application is now fully integrated with Supabase PostgreSQL, with:

Clean relational structure

Primary â†’ Foreign key mapping

Consistent FastAPI transaction flow

ML + UI + API + DB working end-to-end